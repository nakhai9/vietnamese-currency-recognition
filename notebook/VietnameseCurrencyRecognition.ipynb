{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" System Processing \"\"\"\n",
    "import os\n",
    "from time import time\n",
    "\"\"\" Dataset Processing \"\"\"\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "\"\"\" Image Processing \"\"\"\n",
    "import cv2\n",
    "from PIL import Image\n",
    "# In Google Colab: cv2_imshow() instead of cv2.imshow() OpenCV\n",
    "# from google.colab.patches import cv2_imshow\n",
    "# % matplotlib inline\n",
    "\"\"\"\"\"\"\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\" Support Vector Machine \"\"\"\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\"\"\"\"\"\"\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Working with data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataset(CSV_PATH):\n",
    "  \"\"\"\n",
    "    Make a image dataset\n",
    "    Args:\n",
    "      CSV_PATH (str): path to File.csv for storing data\n",
    "      folders (list): \n",
    "  \"\"\"\n",
    "  IMAGE_SIZE = 28\n",
    "  folders = ['10', '20', '50', '100', '200', '500']\n",
    "  for folder in folders:\n",
    "    for imgFile in os.listdir(folder):\n",
    "      image = cv2.imread(f\"{folder}/{imgFile}\")\n",
    "      try:\n",
    "        image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        newImage = image.reshape(1, -1)\n",
    "        row = newImage[0].tolist()\n",
    "        # assign label for vector\n",
    "        row.insert(0, int(folder))\n",
    "        with open(CSV_PATH, 'a') as file:\n",
    "          writer = csv.writer(file)\n",
    "          writer.writerow(row)\n",
    "      except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(path, header):\n",
    "  \"\"\"\n",
    "    GET dataset on Github\n",
    "    @param path {string}: link to github\n",
    "    Returns: \n",
    "      {[]}: there are 4 array: xtrain, xtest, ytrain, ytest\n",
    "  \"\"\"\n",
    "  try:\n",
    "    VietNamMoneyDataset = pd.read_csv(path, header=header)\n",
    "\n",
    "    X = VietNamMoneyDataset.iloc[:,1:]\n",
    "    label = VietNamMoneyDataset.iloc[:,:1]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, label, test_size=0.4)\n",
    "    \n",
    "    return np.array(X_train.values.tolist()), np.array(X_test.values.tolist()), np.array(y_train), np.array(y_test)\n",
    "    \n",
    "  except:\n",
    "    return np.array([]), np.array([]), np.array([]), np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDatasetShape(X_train, X_test, y_train, y_test):\n",
    "  try:\n",
    "    print(f'Shape of X_train: {X_train.shape}')\n",
    "    print(f'Shape of X_test: {X_test.shape}')\n",
    "    print(f'Shape of y_train: {y_train.shape}')\n",
    "    print(f'Shape of y_test: {y_test.shape}\\n')\n",
    "  except:\n",
    "    print(f'Error occured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Get currency by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExchangeRate(path):\n",
    "     exchangeRate = []\n",
    "     tree = ET.parse('exchangeRate_Vietcombank.xml')\n",
    "     root = tree.getroot()\n",
    "     for x in root.findall('Exrate'):\n",
    "          # print(x.attrib)\n",
    "          # print(type(x.attrib))\n",
    "          # print(x.attrib['CurrencyCode'])\n",
    "          # transfer = x.attrib['Transfer'].replace(',', '')\n",
    "          # print(round(10000 / float(transfer), 4))\n",
    "          exchangeRate.append(\n",
    "               {\n",
    "                    'CurrencyName': x.attrib['CurrencyName'].strip(),\n",
    "                    'CurrencyCode': x.attrib['CurrencyCode'].strip(),\n",
    "                    'CurrencyTransfer': float(x.attrib['Transfer'].replace(',', '').strip())\n",
    "               }\n",
    "          )\n",
    "     return exchangeRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCurrencyTransfer(code):\n",
    "     for item in getExchangeRate('exchangeRate_Vietcombank.xml'):\n",
    "          if item['CurrencyCode'] == code:\n",
    "               return item['CurrencyTransfer'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCurrencyById(id):\n",
    "     labels = [\n",
    "          {  \"id\": 10, \"value\": \"Ten Thousand Vietnam Dongs\", 'denomination': 10000},\n",
    "          {  \"id\": 20, \"value\": \"Two Thousand Vietnam Dongs\", 'denomination': 20000}, \n",
    "          {  \"id\": 50, \"value\": \"Five Thousand Vietnam Dongs\", 'denomination': 50000 }, \n",
    "          {  \"id\": 100, \"value\": \"One Hundred Thousand VND\", 'denomination': 100000}, \n",
    "          {  \"id\": 200, \"value\": \"Two Hundred Thousand VND\", 'denomination': 200000}, \n",
    "          {  \"id\": 500, \"value\": \"Five Hundred Thousand VND\", 'denomination': 500000},\n",
    "     ]\n",
    "     for i in labels:\n",
    "          if i['id'] == id:\n",
    "               return i['value'], i['denomination']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Working with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModelWithParameters(X, y, params):\n",
    "  model = GridSearchCV(SVC(), params, refit=True, verbose=10)\n",
    "  model.fit(X, y)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestParameters(model):\n",
    "  return model.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Working with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArrayFromImage(path, mode):\n",
    "  \"\"\"\n",
    "    path: String\n",
    "    mode: RGB, GRAYSCALE\n",
    "    default: RGB\n",
    "  \"\"\"\n",
    "  IMAGE_SIZE = (28, 28)\n",
    "  if mode == 'RGB':\n",
    "    image = cv2.imread(path)\n",
    "  else:\n",
    "    image = cv2.imread(path, 0)\n",
    "  image = cv2.resize(image, IMAGE_SIZE)\n",
    "  Image = image.reshape(1, -1)\n",
    "  return Image / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Working with confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(y_val, y_pred):\n",
    "     confusionMatrix = confusion_matrix(y_val, y_pred)\n",
    "     return confusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawConfusionMatrix(confusionMatrix, numberOfClass ):\n",
    "     print()\n",
    "     df_cm = pd.DataFrame(confusionMatrix, range(numberOfClass), range(numberOfClass))\n",
    "     # plt.figure(figsize=(10,7))\n",
    "     # sns.set(font_scale=1.4) # for label size\n",
    "     plt.figure(figsize = (10,7))\n",
    "     sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 12}) # font size\n",
    "     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Load data from CSV file on Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://raw.githubusercontent.com/nguyenanhkhai/Vietnamese-Currency-Recognition/master/dataset/RGB.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (551, 2352)\n",
      "Shape of X_test: (368, 2352)\n",
      "Shape of y_train: (551, 1)\n",
      "Shape of y_test: (368, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, x_val, y, y_val = getDataset(URL, header=None)\n",
    "printDatasetShape(x, x_val, y, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x / 255.0\n",
    "\n",
    "x_val = x_val / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Applying Principal Component Analysis on data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=60\n",
    "\n",
    "pca = PCA(n_components=N)\n",
    "\n",
    "pca.fit(x)\n",
    "\n",
    "pcaX = pca.transform(x)\n",
    "\n",
    "pcaX_val = pca.transform(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Declare params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = [\n",
    "           {'C': [i for i in range(1, 100)], 'degree': [1,2,3,4,5], 'kernel': ['poly'], 'gamma': [ *['auto', 'scale'], *[i/10 for i in range(20)]],'cache_size': [3000], 'probability': [True]},\n",
    "           {'C': [i for i in range(1, 100)], 'gamma': [ *['auto', 'scale'], *[i/10 for i in range(20)]], 'kernel': ['rbf'], 'cache_size': [3000], 'probability': [True]},\n",
    "           {'C': [i for i in range(1, 100)], 'kernel': ['linear'], 'random_state': [0]}\n",
    "]\n",
    "\n",
    "# params2 = {\n",
    "#     'kernel': ['poly', 'rbf', 'linear'],\n",
    "#     'C': [1, 10, 100, 1000],\n",
    "#     'degree': [i/10 for i in range(50)],\n",
    "#     'gamma': [ *['auto', 'scale'], *[i/10 for i in range(20)]],\n",
    "#     'cache_size': [3000],\n",
    "#     'probability': [True]\n",
    "# }\n",
    "\n",
    "rbfParams = [\n",
    "        {\n",
    "                'C': [1, 10, 100],\n",
    "                'gamma': [ *['auto', 'scale'], *[i/10 for i in range(20)]],\n",
    "                'kernel': ['rbf'],\n",
    "                'cache_size': [3000],\n",
    "                'probability': [True]\n",
    "        }\n",
    "]\n",
    "\n",
    "polyParams = [\n",
    "        {\n",
    "                'C': [1, 10, 100],\n",
    "                'degree': [1,2,3,4,5],\n",
    "                'kernel': ['poly'],\n",
    "                'gamma': [ *['auto', 'scale'], *[i/10 for i in range(20)]],\n",
    "                'cache_size': [3000],\n",
    "                'probability': [True]\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Build a model with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "newY = [i[0] for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "model = trainModelWithParameters(pcaX, newY, params1)\n",
    "end = time()\n",
    "\n",
    "print(f'Train Time: { end-start }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Find best parameters for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Parameters is: {model.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Accuracy and FMeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_with_train = model.predict(pcaX)\n",
    "# y_pred_with_train\n",
    "\n",
    "accuracyWithTrainSet = accuracy_score(y, y_pred_with_train)\n",
    "f1ScoreWithTrainSet = f1_score(y, y_pred_with_train, average= \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracyWithTrainSet * 100} %\")\n",
    "print(f\"f1 score: {f1ScoreWithTrainSet}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_with_test = model.predict(pcaX_val)\n",
    "# y_pred_with_test\n",
    "\n",
    "accuracyWithTestSet = accuracy_score(y_val, y_pred_with_test)\n",
    "f1ScoreWithTestSet = f1_score(y_val, y_pred_with_test, average= \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracyWithTestSet * 100} %\")\n",
    "print(f\"f1 score: {f1ScoreWithTestSet}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Using 5-fold for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainUsingKFold(X, y):\n",
    "  kf = KFold(n_splits=5, shuffle=True)\n",
    "  accuracy = []\n",
    "  for train_index, test_index in kf.split(X):\n",
    "    # print('Train:', train_index, 'Test:', test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # print(X_train.shape)\n",
    "    # print(X_test.shape)\n",
    "\n",
    "    model = SVC(C=100, cache_size=3000, gamma='auto', kernel='rbf', probability=True)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "  \n",
    "  for value in accuracy:\n",
    "    print(f'Result:{value}')\n",
    "  print(f'Avarage: {sum(accuracy) / 5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainUsingKFold(pcaX, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainUsingKFold(pcaX_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfs = confusionMatrix(y, y_pred_with_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cfs = confusionMatrix(y_val, y_pred_with_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = test_cfs / np.sum(test_cfs)\n",
    "\n",
    "ax = sns.heatmap(percent, annot=True, fmt='.2%', cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Precision, Recall and FMeasure index on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(pcaX_val, y_val)\n",
    "Y_score = model.predict(pcaX_val)\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_val, Y_score, average=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "data = np.array([0.56097561, 0.82, 0.51785714, 0.66666667, 0.6, 0.68055556]) * 100\n",
    "labels = ['10,000', '20,000', '50,000', '100,000', '200,000', '500,000']\n",
    "plt.xticks(rotation=50)\n",
    "plt.xticks(range(len(data)), labels, fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Nhãn', fontsize=15)\n",
    "plt.ylabel('Precision (%)', fontsize=15)\n",
    "plt.title('Chỉ số Precision cho mỗi lớp', fontsize=15)\n",
    "plt.bar(range(len(data)), data, color=['#597dbf', '#d98b5f', '#75bf71', '#c76e6e', '#9475ab', '#d08abb']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "data = np.array([0.67647059, 0.68333333, 0.53703704, 0.58181818, 0.61016949, 0.68055556]) * 100\n",
    "labels = ['10,000', '20,000', '50,000', '100,000', '200,000', '500,000']\n",
    "plt.xticks(rotation=50)\n",
    "plt.xticks(range(len(data)), labels, fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Nhãn', fontsize=15)\n",
    "plt.ylabel('Recall (%)', fontsize=15)\n",
    "plt.title('Chỉ số Recall cho mỗi lớp', fontsize=15)\n",
    "plt.bar(range(len(data)), data, color=['#597dbf', '#d98b5f', '#75bf71', '#c76e6e', '#9475ab', '#d08abb']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "data = np.array([0.61333333, 0.74545455, 0.52727273, 0.62135922, 0.60504202, 0.68055556]) * 100\n",
    "labels = ['10,000', '20,000', '50,000', '100,000', '200,000', '500,000']\n",
    "plt.xticks(rotation=50)\n",
    "plt.xticks(range(len(data)), labels, fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Nhãn', fontsize=15)\n",
    "plt.ylabel('F Score (%)', fontsize=15)\n",
    "plt.title('Chỉ số F score cho mỗi lớp', fontsize=15)\n",
    "plt.bar(range(len(data)), data, color=['#597dbf', '#d98b5f', '#75bf71', '#c76e6e', '#9475ab', '#d08abb']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Image list for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = '../test/'\n",
    "imageList = os.listdir(store)\n",
    "imageList = [f'{store}/{item}' for item in imageList]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord = 1\n",
    "for image in imageList:\n",
    "  principalComponentAnalysis = pca.transform(getArrayFromImage(image, mode='RGB'))  \n",
    "  result = model.predict(principalComponentAnalysis)\n",
    "  \n",
    "  ord = ord + 1\n",
    "\n",
    "  print(f\"Name of image: {image}\")\n",
    "  print(f'Label: {getCurrencyById(result[0])[0]}')\n",
    "  # img = cv2.resize(cv2.imread(image), (300, 300))\n",
    "  # cv2_imshow(img)\n",
    "  # cv2.imshow('Hello',img)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL = '../app/model.pkl'\n",
    "PATH_TO_PKL = './app/model.pca'\n",
    "pickle.dump(model, open(f'{PATH_TO_MODEL}', 'wb'))\n",
    "pickle.dump(pca, open(f\"{PATH_TO_MODEL}\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 Download exchange rate file from Vietcombank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve('https://portal.vietcombank.com.vn/Usercontrols/TVPortal.TyGia/pXML.aspx', 'exchangeRate.xml')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbb2d603b8abaf56571341f8d455fad24c4dfbd34b368810c960e48ad7526bb9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
